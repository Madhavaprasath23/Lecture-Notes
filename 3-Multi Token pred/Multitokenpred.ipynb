{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQFrItJp7VkM",
        "outputId": "6ac7dc89-43ca-477b-f4a7-a3354f8a85f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ponniyin-selvan-'...\n",
            "remote: Enumerating objects: 341, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 341 (delta 0), reused 0 (delta 0), pack-reused 338\u001b[K\n",
            "Receiving objects: 100% (341/341), 1.79 MiB | 11.23 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rahulvks/ponniyin-selvan-"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-nlp-library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXIYP6etXyP_",
        "outputId": "21d89b4b-5f3b-4546-b485-bdedd9dfc671"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx-argparse (from indic-nlp-library)\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
            "  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting morfessor (from indic-nlp-library)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.1)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-argparse->indic-nlp-library) (5.0.2)\n",
            "Requirement already satisfied: docutils<0.21 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.18.1)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.8)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.6)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.10)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.7)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.4)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.16.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.15.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.16)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2024.7.4)\n",
            "Installing collected packages: morfessor, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.4.0 sphinx-rtd-theme-2.0.0 sphinxcontrib-jquery-4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-xX3rl-pX4SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "try:\n",
        "  import einops\n",
        "  from einops import rearrange,reduce,repeat\n",
        "except:\n",
        "  !pip install einops\n",
        "  import einops\n",
        "  from einops import rearrange,reduce,repeat\n",
        "import torch.nn.functional as F\n",
        "import math"
      ],
      "metadata": {
        "id": "qpwwdY98Nzt3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "poABRxLP74C2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f6f1b6d6-f8c7-4656-aec9-e846e8be3972"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'with open(\"total_corpus.txt\",\\'w\\') as f:\\n  f.write(total_corpus)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm.notebook import tqdm\n",
        "def sorted_value(x):\n",
        "  return float(x.split('/')[-2].split('-')[-1]),int(x.split('/')[-1].split('_')[-1].split('.')[0])\n",
        "text_files = sorted(glob.glob('/content/ponniyin-selvan-/**/*.txt'),key=sorted_value)\n",
        "total_corpus=''\n",
        "numpy_tokens=[]\n",
        "for file in text_files:\n",
        "  with open(file,'r') as f:\n",
        "    words=f.readline()\n",
        "    words=words.split(' ')[3:]\n",
        "    current_word= ' '.join(words)\n",
        "    arr=tokenizer(current_word,add_special_tokens=False).input_ids\n",
        "    numpy_tokens=arr if numpy_tokens==[] else numpy_tokens+arr\n",
        "\n",
        "\n",
        "\"\"\"with open(\"total_corpus.txt\",'w') as f:\n",
        "  f.write(total_corpus)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_tokens=np.array(numpy_tokens,dtype=np.int16)\n",
        "with open('tokens.npy','wb') as f:\n",
        "  np.save(f,numpy_tokens)"
      ],
      "metadata": {
        "id": "osui-EaSktrt"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size=32"
      ],
      "metadata": {
        "id": "MhRG3FgaRpdx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MHA(nn.Module):\n",
        "  def __init__(self,n_heads,n_embd,attention_drop=0):\n",
        "    super().__init__()\n",
        "    self.head_size=n_embd//n_heads\n",
        "    self.n_heads=n_heads\n",
        "    self.attn_drop=attention_drop\n",
        "    self.qkv=nn.Linear(n_embd,n_embd*3)\n",
        "    self.dropout=nn.Dropout(self.attn_drop)\n",
        "    self.out=nn.Linear(n_embd,n_embd)\n",
        "\n",
        "  def forward(self,x):\n",
        "    B,T,C=x.shape\n",
        "    C//=self.n_heads\n",
        "    qkv= rearrange(self.qkv(x),'B T (C s)-> s B T C',s=self.n_heads)\n",
        "    q,k,v=rearrange(qkv,'heads B T (C split)-> split B heads T C',split=3)\n",
        "    out=F.scaled_dot_product_attention(q,k,v,is_causal=True)\n",
        "    out=rearrange(out,\"B heads T C -> B T (C heads)\")\n",
        "    return self.out(out)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "\n",
        "  def __init__(self,n_embd,dropout=0):\n",
        "    super().__init__()\n",
        "    self.net=nn.Sequential(\n",
        "        nn.Linear(n_embd,4*n_embd),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(4*n_embd,n_embd),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self,n_embd,n_head,dropout=0):\n",
        "    super().__init__()\n",
        "\n",
        "    self.sa = MHA(n_head,n_embd,dropout)\n",
        "    self.ffwd= FeedForward(n_embd,dropout)\n",
        "\n",
        "    self.ln1= nn.LayerNorm(n_embd)\n",
        "    self.ln2=nn.LayerNorm(n_embd)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    sa=self.sa(self.ln1(x))\n",
        "\n",
        "    x= x+ sa\n",
        "    x= x+ self.ffwd(self.ln2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "VMZEN3ocC5ot"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Block(768,8)"
      ],
      "metadata": {
        "id": "ZNQdxnkZPn3x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertTokenizer\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained(\"ai4bharat/IndicBART\", do_lower_case=False, use_fast=False, keep_accents=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "d5ac319a5f814c3ea08e5c1d34075a47",
            "99eb1ba125294033b357ef962d3f2ccf",
            "6feaeffdcb75445baeb30e52191b2f34",
            "87db6b2323024f69ae8bf3e09b058201",
            "fe07602ee43f4cb489024c6d36b1d7d7",
            "fd0f97823e7c4e19b6ccdfbb564d8ffd",
            "0b6d3b805614498b872040b220749597",
            "5a076a1b8d7240fd88025b54c3da037b",
            "950545a7f715444da777c31c9f8d3fd0",
            "0fc4ff100c7c4ff796eda147d451e3cd",
            "25f49a4158e34da1b24b0782fc43b5b1"
          ]
        },
        "id": "Yhq4wUhOQ0vA",
        "outputId": "f0de51ed-07fb-40c6-bb69-68a8196a22c3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/976M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5ac319a5f814c3ea08e5c1d34075a47"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = \"ந\"\n",
        "inp = tokenizer(input_sentence, add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids\n",
        "print(\"Original input sentence:\", input_sentence)\n",
        "print(\"Segmented input sentence:\", tokenizer.convert_ids_to_tokens(inp[0]))\n",
        "print(\"Orginal Again:\",tokenizer.decode(inp[0]))\n",
        "print(\"Input sentence as tensor: \", inp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF9IDfkzYbe1",
        "outputId": "59f79f09-8e92-43a0-cb5d-5fb2f5c634fa"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original input sentence: ந\n",
            "Segmented input sentence: ['▁', 'ந']\n",
            "Orginal Again: ந\n",
            "Input sentence as tensor:  tensor([[   41, 60827]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"total_token_count in INDICBART is  64014  so we will Intialize the particular Embedding matrix with the same number of tokens and with decoder only block and finally with Linear layer,\n",
        "Pretraining from the Poniyan selvan tamil corpus\"\"\""
      ],
      "metadata": {
        "id": "gEa4Vz_jaVJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def position_sin_cos(n_emb,context):\n",
        "\n",
        "  assert n_emb%2\n",
        "\n",
        "  pe=torch.zeros(context,n_emb)\n",
        "  position=torch.arange(0,length).unsqueeze(1).float()\n",
        "  div_term=torch.exp((torch.arange(0,n_emb,2,dtype=torch.float)) * -(math.log(10000)/d_model))\n",
        "\n",
        "  pe[:,0::2] =  torch.sin(position*div_term)\n",
        "  pe[:,1::2] =  torch.cos(position*div_term)\n",
        "\n",
        "  return pe\n"
      ],
      "metadata": {
        "id": "nmhWb4OFx4am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiToken_prediction(nn.Module):\n",
        "  def __init__(self,n_emb,n_heads,drop_out_blocks=0.0,n_heads_last=1,layers=4):\n",
        "\n",
        "    self.vocab_size=64014\n",
        "    self.n_emb=n_emb\n",
        "    self.context_size=context_size # for now we make it sin cos\n",
        "    self.n_layers=layers\n",
        "    self.n_heads_last=n_heads_last\n",
        "\n",
        "    self.pe=position_sin_cos(self.n_emb,self.n_context)\n",
        "\n",
        "    self.vocab_size=nn.Embedding(self.vocab_size,self.n_emb)\n",
        "\n",
        "    self.shared_trunk=nn.ModuleList(\n",
        "        [Block(n_emb,n_heads) for _ in range(layers)]\n",
        "    )\n",
        "\n",
        "    self.independent_heads(\n",
        "        [MHA(n_head,n_emb) for i in range(layers)]\n",
        "    )\n",
        "    self.ln_norm=nn.LayerNorm(self.n_emb)\n",
        "    self.lm_head=nn.Linear(self.n_emb,self.vocab_size,bias=False)\n",
        "\n",
        "    self.vocab_size.weights=self.lm_head.weights\n",
        "\n",
        "    self.apply(_init_weights)\n",
        "\n",
        "  def _init_weights(self,module):\n",
        "    if isinstance(module,nn.Linear):\n",
        "      std=0.02 * (2*self.layers) ** -0.5\n",
        "\n",
        "      torch.nn.init.normal_(module.weight,mean=0.0,std=std)\n",
        "\n",
        "      if module.bias is not None:\n",
        "        torch.nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module,nn.Embedding):\n",
        "      torch.nn.init.normal_(module.weight,mean=0.0,std=0.02)\n",
        "\n",
        "  def forward_shared_trunk(self,idx):\n",
        "\n",
        "    batch,context=idx.shape\n",
        "\n",
        "    x= self.vocab_size(idx) + self.pe\n",
        "\n",
        "    for block in self.shared_trunk:\n",
        "      x=block(x)\n",
        "\n",
        "    x=self.ln_norm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "kkME4wdYiI2k",
        "outputId": "a0ac3d96-b033-4ed0-c798-0952d6b22b74"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-73-77b81fa9d043>, line 37)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-73-77b81fa9d043>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataloader:\n",
        "  def __init__(self,B,T,tokens_to_pred):\n",
        "    self.B=B\n",
        "    self.T=T\n",
        "    self.current_position=0\n",
        "    self.tokens_to_pred=tokens_to_pred\n",
        "    self.reset()\n",
        "  def reset(self):\n",
        "    self.current_position=0\n",
        "    np_tokens=np.load(\"tokens.npy\")\n",
        "    np_tokens=np_tokesn.astype(np.int32)\n",
        "    ptt=torch.tensor(np_tokens,dtype=torch.long)\n",
        "\n",
        "  def next_batch(self):\n",
        "    B,T=self.B,self.T\n",
        "    buf=self.tokens[self.current_position:self.current_position+B*T+4]\n",
        "    X=buf[:-self.tokens_to_pred].view(B,T)\n",
        "    Y=buf[1:]\n",
        "    self.current_position+=B*T\n",
        "\n",
        "    if self.current_position + (B*T+self.tokens_to_pred) > len(self.tokens):\n",
        "      self.reset()\n",
        "\n",
        "    return X,Y\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OjyYSSG6-xTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch_size=2**17\n",
        "B=16\n",
        "T=1024\n",
        "grad_accumulate_steps= total_batch_size // (B*T)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbziyn4P2o5g",
        "outputId": "e946c3ff-5f91-479f-d363-e92b8db3bec8"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131072"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "131072//(64*1024)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W3hnJfkCGxS",
        "outputId": "172b4703-d12a-42b3-c9ca-0028246ddbb0"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model,optimizer,total_grad_accumulation,train_loader,device):\n",
        "  for microstep in range(grad_accumulate_steps):\n",
        "    x,y=train_loader.next_batch()\n",
        "    x,y=x.to(device),y.to(device)\n",
        "\n",
        "    with torch.autocast(device_type=device,dtype=torch.bfloat16):\n",
        "      logits=model.forward()"
      ],
      "metadata": {
        "id": "bWctOBEPCgvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5ac319a5f814c3ea08e5c1d34075a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99eb1ba125294033b357ef962d3f2ccf",
              "IPY_MODEL_6feaeffdcb75445baeb30e52191b2f34",
              "IPY_MODEL_87db6b2323024f69ae8bf3e09b058201"
            ],
            "layout": "IPY_MODEL_fe07602ee43f4cb489024c6d36b1d7d7"
          }
        },
        "99eb1ba125294033b357ef962d3f2ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0f97823e7c4e19b6ccdfbb564d8ffd",
            "placeholder": "​",
            "style": "IPY_MODEL_0b6d3b805614498b872040b220749597",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "6feaeffdcb75445baeb30e52191b2f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a076a1b8d7240fd88025b54c3da037b",
            "max": 976429105,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_950545a7f715444da777c31c9f8d3fd0",
            "value": 976429105
          }
        },
        "87db6b2323024f69ae8bf3e09b058201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fc4ff100c7c4ff796eda147d451e3cd",
            "placeholder": "​",
            "style": "IPY_MODEL_25f49a4158e34da1b24b0782fc43b5b1",
            "value": " 976M/976M [00:15&lt;00:00, 63.2MB/s]"
          }
        },
        "fe07602ee43f4cb489024c6d36b1d7d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd0f97823e7c4e19b6ccdfbb564d8ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b6d3b805614498b872040b220749597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a076a1b8d7240fd88025b54c3da037b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "950545a7f715444da777c31c9f8d3fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fc4ff100c7c4ff796eda147d451e3cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25f49a4158e34da1b24b0782fc43b5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}